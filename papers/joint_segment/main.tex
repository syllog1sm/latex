% vim: set textwidth=78 fo+=t :

\documentclass[11pt,letterpaper]{article}
\usepackage{acl2013}
\usepackage{amsmath, amsthm}
\usepackage{times}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage{natbib}
\usepackage{amsfonts}
\usepackage{tikz-dependency}
\usepackage{placeins}
\usepackage{xcolor}
\usepackage[noend]{algpseudocode}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{lcovington}
\usepackage{cancel}
% Alter some LaTeX defaults for better treatment of figures:
    % See p.105 of "TeX Unbound" for suggested values.
    % See pp. 199-200 of Lamport's "LaTeX" book for details.
    %   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.8}	% max fraction of floats at bottom
    %   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \setcounter{dbltopnumber}{2}    % for 2-column pages
    \renewcommand{\dbltopfraction}{0.9}	% fit big float above 2-col. text
    \renewcommand{\textfraction}{0.07}	% allow minimal text w. figs
    %   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.7}	% require fuller float pages
	% N.B.: floatpagefraction MUST be less than topfraction !!
    \renewcommand{\dblfloatpagefraction}{0.7}	% require fuller float pages

	% remember to use [htp] or [htpb] for placement


\setlength\titlebox{6.5cm}    % Expanding the titlebox


\renewcommand{\tabcolsep}{5pt}

\newcommand{\baseacc}{00.00\xspace}
\newcommand{\sysacc}{00.00\xspace}
\newcommand{\sysimprove}{00.00\xspace}
\newcommand{\las}{\textsc{las}\xspace}
\newcommand{\uas}{\textsc{uas}\xspace}
\newcommand{\pp}{\textsc{pp}\xspace}
\newcommand{\pos}{\textsc{pos}\xspace}
\newcommand{\wsj}{\textsc{wsj}\xspace}
\newcommand{\edittrans}{\textsc{edit}\xspace}

\newcommand{\stacktop}{S$_0$\xspace}
\newcommand{\buffone}{N$_0$\xspace}

\newcommand{\tuple}[1]{$\langle#1\rangle$}
\newcommand{\maybe}[1]{\textcolor{gray}{#1}}
\newcommand{\note}[1]{\textcolor{red}{#1}}
\newcommand{\state}{\mathcal{S}}
\newcommand{\nmae}{\textsc{nmae}\xspace}
\newcommand{\pcfg}{\textsc{pcfg}\xspace}

\newcommand{\szero}{S0\xspace}
\newcommand{\nzero}{N0\xspace}

\newcommand{\szeroH}{S0$_h$\xspace}
\newcommand{\szeroHH}{S0$_{h2}$\xspace}
\newcommand{\szeroL}{S0$_L$\xspace}
\newcommand{\szeroLL}{S0$_{L2}$\xspace}
\newcommand{\szeroR}{S0$_R$\xspace}
\newcommand{\szeroRR}{S0$_{R2}$\xspace}
\newcommand{\szeroLzero}{S0$_{L0}$\xspace}
\newcommand{\szeroRzero}{S0$_{R0}$\xspace}

\newcommand{\nzeroL}{N0$_L$\xspace}
\newcommand{\nzeroLL}{N0$_{LL}$\xspace}
\newcommand{\nzeroLzero}{N0$_{L0}$\xspace}

\newcommand{\szeroRedge}{S0$_{re}$\xspace}
\newcommand{\szeroLedge}{S0$_{le}$\xspace}
\newcommand{\nzeroLedge}{N0$_{le}$\xspace}

\newcommand{\sparseval}{\textsc{sparseval}\xspace}

\title{Incremental Parsing of Disfluent, Unsegmented Speech Transcripts}

\author{
	Anonymous\\
  	Department\\
  	Institution\\
  	Address\\
  {\tt \small email }\\
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We present a joint transition-based model of segmentation, disfluency detection
and dependency parsing.  We evaluate two ways of encoding the segmentation
decisions into the transition system, and compare against a pipeline approach,
where the input is segmented with a \textsc{crf} model before parsing.
We find that the joint model achieves 1.5\% better parse accuracy, and 0.5\% better
disfluency $F$-measure.
Our final unlabelled parse accuracy is 87.6\%, the best score on
unsegmented speech input that we are aware of.
\end{abstract}

% P1
\section{Introduction}

Previous speech understanding systems have required that the input be
pre-segmented into sentence-like units. 
For example, the following turn from one of the Switchboard conversational speech
transcripts is segmented into three utterances, at the slashes:

\begin{lexample}
\small
uh and really we were really forced into keeping a budget because i 'm i 'm paid once a month which sort of sort of forces some uh uh restrictions / \\
and you need to make sure all your bills are paid / \\
uh about yourself
\end{lexample}

\noindent 
The assumption has been that segmentation
is necessary to make parsing tractable, as until recently the most accurate parsing
systems were polynomial time.  Disfluencies such as filled-pauses and speech
errors have also been addressed through pre-processes.
The main strategy of previous work has been to adopt a pipeline
architecture, where the input is progressively transformed to resemble well-edited
written texts.

However, recent work has shown that a pipeline architecture is inferior for detecting
speech-repairs.  \citet{rasooli:13} and Honnibal and Johnson (2014)
describe two joint
transition-based models that detect speech-repair disfluencies at parse-time,
instead of as a pre-process.  Honnibal and Johnson show that their model out-performs
a pipeline of state-of-the-art components.  We adopt a similar model, although
we adopt a transition-system simplification from \citet{kuhlmann:11}, and integrate
the detection of filled-pauses and other non-repair disfluencies into the model.

In this paper, we show that this joint approach can be successfully extended
to segmentation.  We present a joint transition-based model that predicts
segment boundaries, repair and non-repair disfluencies, syntactic heads, and
dependency labels.  The system runs in expected linear-time, and achieves
state-of-the-art accuracy.

For comparison, we prepared a standard \textsc{crf}-based segmentation system,
which achieved 96.5\% accuracy.  Features were based on the word and part-of-speech
tag context.  No phonetic features were used in any of our experiments.

We find that the joint model performs significantly better than the pipeline approach.
We attribute the difference in performance to error-propagation
problems inherent in the pipeline approach.  When the segmenter makes an error,
it leaves the parser with mistaken input, for which the parser may not be able
to find a satisfactory parse.  Jointly determining the segmentation and parsing
solves this problem.  Despite slightly lower segmentation accuracy, the joint
model achieves 87.6\% parse accuracy, substantially higher than the 86.1\%
accuracy of the pipeline approach.

\begin{figure}
    \begin{tabular}{l}

        A flight to $\underbrace{\mathrm{um}}_\text{FP} \underbrace{\mathrm{Boston}}_\text{RM} \underbrace{\mathrm{I\;mean}}_\text{IM} \underbrace{\mathrm{Denver}}_\text{RP}$ Tuesday\\

\end{tabular}
\caption{\small A sentence with disfluencies annotated in the style of Shriberg (1994) 
    and the Switchboard corpus.
FP=Filled Pause, RM=Reparandum, IM=Interregnum, RP=Repair.
We follow previous work in evaluating the system on the accuracy with which
it identifies speech-repairs, marked \emph{reparandum} above.
\label{fig:shriberg}}
\end{figure}


\section{Spoken Language Understanding}

Unscripted speech has several characteristics that make spoken language understanding
a distinct problem from understanding written text.  Two such features are that
it is \emph{continuous}, and that it is frequently \emph{disfluent}.

Well-edited text can be segmented into sentences easily, using punctuation and
capitalisation.  Sentence boundary detection systems typically achieve accuracies
above 99\%.  For speech, the problem is much more difficult.  Previous work has
explored the idea that pauses and other phonetic features could compensate
for the lack of orthographic cues \citep{mischa:??}.  However, even the
successful attempts to use phonetic features have yielded only small accuracy
improvements \citep{isi}.

As well as being continuous, unscripted speech is frequently disfluent.
Figure \ref{fig:shriberg} shows part of an utterance, with a speech-repair annotated
with the scheme devised by \citet{shriberg:94}.  The words marked \emph{reparandum}
are corrected by the speaker, often with an explicit editing term in the
\emph{interregnum}, before being replaced by the text marked \emph{repair}.
Speech repairs are a particularly problematic for syntactic
parsers, because of the complicated dependency structures that can arise between the
reparandum, repair and the fluent sentence \citep{johnson:05}.

\begin{table}
\centering
\small
\begin{tabular}{l|rr}
    \hline
    Length & Segmented & Unsegmented \\
    \hline \hline
    1-2 & 26,140 & 10,225 \\
    2-5 & 15,727 & 6,914 \\
    5-10 & 23,283 & 6,885 \\
    10-20 & 19,738 &  8,934 \\
    20-50 & 6,406 & 9,765 \\
    50-100 & 161 & 2,106 \\
    100-200 & 0 & 257 \\
    200-500 & 0 & 20 \\
    \hline
    Total & 91,455 & 45,106 \\
    \hline
\end{tabular}
\caption{\small Input lengths in the Switchboard training corpus, with and without
    gold-standard segmentation.  For instance, with utterances pre-segmented,
    there are 161 sentences with between 51 and 100 tokens; in the unsegmented
corpus, there are 2,106 sentences with lengths in that range.
\label{tab:seg_freqs}}
\vspace*{-3em}
\end{table}

\subsection{The Switchboard Corpus}

The Switchboard portion of the Penn Treebank \citep{marcus:93} contains 1,126
transcripts of telephone calls between strangers, on an assigned topic.
Every file has been annotated for speech-repairs and other disfluencies (filled
pauses, parentheticals, discourse markers, etc); these annotations are provided
in the \textsc{dps} files.  Syntactic brackets (\textsc{mrg} files) are available
for 619,236 of the 1,482,845 words in the training sections of the corpus (2 and 3). 
All of the transcripts have also been annotated for various speech \emph{metadata},
including utterance segmentation, speech repairs per \citet{shriberg:94}, and 
non-repair disfluencies, such as filled pauses.  Table \ref{tab:dfl_freqs} shows the
frequency of these disfluencies in the training corpus.

\begin{table}
    \centering
    \small
    \begin{tabular}{lc|r}
\hline
Disfluency type & Example & Freq. \\
\hline \hline
Reparanda & \emph{to } \textbf{Boston} \emph{uh Denver} & 32,310 \\
Filled pauses    & \textbf{um}, \textbf{uh} & 20,502 \\
Edit terms & \textbf{I mean} & 3,447 \\ 
Discourse  & \textbf{well}, \textbf{you know} & 21,412  \\
Segment Conjunctions & \textbf{and}, \textbf{and so} & 25,624 \\
\hline
\end{tabular}
\caption{\small Frequencies of different disfluency types in Sections 2 and 3 of the
Switchboard \textsc{mrg} files.\label{tab:dfl_freqs}}
\vspace*{-0.5in}
\end{table}

Table \ref{tab:seg_freqs} shows how segmentation affects the length of training
inputs.  Without any utterance segmentation, the inputs consist of whole turns,
using the gold-standard diarisation in the \textsc{mrg} files.
Segmentation doubles the number of inputs (and so halves their length, on average);
i.e., on average each turn contains one segment boundary.

The Switchboard syntactic annotations come in the form of syntactic brackets.
We follow Honnibal and Johnson (2014) in using
the 2013-04-05 version of the Stanford dependency converter \citep{stanford_deps},
using the Basic Dependencies scheme,
which produces strictly projective representations.

We follow previous work on disfluency detection by lower-casing the text and
removing punctuation and partial words (words tagged XX and words ending in
`-').  However, we depart from Honnibal and Johnson (2014) in not removing one-token
sentences, and not removing filled pauses as a pre-process, and not
re-tokenising the common parentheticals \emph{you know} and \emph{i mean}.
We avoid these extra pre-processing steps in favour of extended disfluency processing,
using a new transition we dub \textbf{Delete}.  This transition is described in
Section \ref{sec:delete}.

\section{Joint Disfluency Detection and Parsing}

Our model is based on the joint incremental disfluency detection and parsing
system described by Honnibal and Johnson (2014).  We briefly describe how the
system works in this section, before introducing our novel contributions from
Section 4 onwards.

\subsection{Transition-based Dependency Parsing}

\subsection{The Edit Transition}

\subsection{Decoding}

\subsection{Training}

\subsection{Features}

\subsection{POS Tagging}

\clearpage

\section{Joint Segmentation and Parsing}

\subsection{Segment (leaf)}

The ``leaf'' version of the Segment transition, abbreviated S$_L$, is applied when
the last word of a segment is on the stack, and the first word of the next segment
is at the start of the buffer.

Additionally, the Shift, Left and Edit moves are updated with a additional
pre-condition, that stipulates they cannot be applied when S0 and N0 have
been assigned different sentence IDs.  The transition increments the sentence
ID of N0, which acts as a flag that blocks these transitions until the stack is clear.
While the parser is in this `break mode', the only transitions available are
Right and Filler.

The pre-conditions on the transition stipulate that it can only be applied when
S0 has no right children, and N0 has no left children.  This ensures the segment
boundary is inserted between two leaves of the tree.

\subsection{Segment (governors)}

In this segmentation strategy, the governors are accumulated on the stack, and
popped once the parser reaches the end of the buffer.  The segment boundary is
inserted between their rightmost and leftmost leaf words.
The transition is stated:

\begin{eqnarray}
    (\sigma | i | j, \emptyset , A, D) \vdash (\sigma, | i, \emptyset, A, D, S_i \ne S_j ) & \mathrm{S}_G
\end{eqnarray}

That is, if there are at least two words $i$ and $j$ on the stack, and the buffer
is empty, pop $j$ and assert that $i$ and $j$ do not belong to the same segment.

\subsection{Segment between governor and leaf}

In this segmentation strategy, the governors are popped from the stack one at
a time, when the first word of the next segment is at the start of the buffer.

sentence-final punctuation prediction method described by \citet{zhang:13},
in that it 


\begin{figure}
\begin{dependency}[theme=simple, segmented edge]
    \begin{deptext}[column sep=.075cm, row sep=.1ex]
    Clause 1 \& Clause 2 \& Clause 3 \& Clause 4 \& $\langle /s \rangle$ \\
    \end{deptext}
    \depedge{2}{1}{}
    \depedge{3}{2}{}
    \depedge{4}{3}{}
    \depedge{5}{4}{}
    \end{dependency}
    \caption{Left-branching attachment}
\end{figure}

\clearpage
\section{Baseline CRF System}

\section{Experiments}

\section{Results}

\subsection{Choice of Segmentation Strategy}

\begin{table}
    \centering
    \small
    \begin{tabular}{l|rrr}
        System & Parse & Disfl. & Segments \\
        \hline \hline
        S$_G$ & & & \\
        S$_{GL}$  & & & \\
        S$_L$  & & & \\
        \hline
    \end{tabular}
    \caption{\small Comparison of segmentation strategies.}
\end{table}


\subsection{Comparison with Pipeline}

\begin{table}
    \centering
    \small
    \begin{tabular}{l|rrr}
        System & Parse & Disfl. & Segments \\
        \hline \hline
        Seg. $\rightarrow$ Disfl. + Parse & & & \\
        Seg. + Disfl. + Parse  & & & \\
        \hline
        O.Seg. $\rightarrow$ Disfl. + Parse & & & \\
        O.Seg. $\rightarrow$ O.Disfl. $\rightarrow$ Parse & & & \\
        \hline

    \end{tabular}
    \caption{\small Comparison between pipeline, joint, and oracle-pipeline
             approaches.}
\end{table}


\subsection{Test Set Evaluation}

\begin{table}
    \centering
    \small
    \begin{tabular}{l|rrr}
        System & Parse & Disfl. & Seg. \\
        \hline \hline
        Seg. $\rightarrow$ Disfl. + Parse & & & \\
        Seg. + Disfl. + Parse  & & & \\
    \end{tabular}
    \caption{\small Final evaluation.}
\end{table}

%\clearpage

%\section{Related Work}

%\section{Conclusion}
\bibliography{main}
\bibliographystyle{aclnat}


\end{document}
